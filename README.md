# ğŸ“˜LLM-Powered Bible Tutor

A Retrieval-Augmented AI Tutoring System Using GPT-4o-mini, LangChain, and ChromaDB

# ğŸ“–Overview

This project is an AI-powered Catholic Bible tutor that uses Retrieval-Augmented Generation (RAG) to deliver grounded, citation-based responses to user questions.
It semantically indexes the Douayâ€“Rheims Bible (35,800+ verses) and the Compendium of the Catechism of the Catholic Church (2,800+ Q&A items), and provides accurate explanations using GPT-4o-mini.

Unlike typical LLM chatbots, this system never relies on the modelâ€™s memory â€” instead, it retrieves real text from your indexed sources and generates answers grounded in Scripture and Catholic teaching.

# ğŸš€Key Features

Semantic Search with Embeddings
Converts Bible verses and Catechism entries into embeddings using OpenAIâ€™s text-embedding-3-small.

RAG Pipeline (Retrieval-Augmented Generation)
ChromaDB retrieves the most relevant passages; GPT-4o-mini generates grounded explanations.

Multi-Source Retrieval
Retrieves from two separate vector collections:

drb_verses (Douayâ€“Rheims Bible)

ccc_qna (Catechism Compendium)

Grounded, Citation-Based Answers
GPT-4o-mini is prompted to always include Bible verse or paragraph citations.

Batch Embedding Pipeline
Efficiently processes 35k+ verses and 2.8k+ Catechism entries using batch upserts to avoid API limits.

Fully Modular Code
Independent scripts for indexing, inspection, and querying.

# ğŸ§ Tech Stack

Python

OpenAI API (GPT-4o-mini, text-embedding-3-small)

LangChain

ChromaDB (vector database)

tiktoken

pdfplumber (for extracting text for Catechism data)

dotenv

# ğŸ“‚Project Structure
llm-bible-tutor/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ DRC.csv                      # Bible verses (structured)
â”‚   â”œâ”€â”€ catechism_compendium.csv     # Extracted Catechism data
â”‚
â”œâ”€â”€ chroma_db/                       # Auto-generated vector store
â”‚
â”œâ”€â”€ build_index.py                   # Embeds + stores Bible data
â”œâ”€â”€ build_catechism_index.py         # Embeds + stores Catechism data
â”œâ”€â”€ inspect_chroma.py                # Checks collections & samples
â”œâ”€â”€ qa_rag.py                        # Main Bible Tutor RAG script
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                             # Contains OPENAI_API_KEY
â””â”€â”€ README.md

# âš™ï¸Setup Instructions
1. Clone the repo
git clone https://github.com/yourusername/llm-bible-tutor.git
cd llm-bible-tutor

2. Create & activate a virtual environment

Git Bash (Windows):

python -m venv venv
source venv/Scripts/activate

3. Install dependencies
pip install -r requirements.txt

4. Add your API key

Create a .env file:

OPENAI_API_KEY=your-key-here

ğŸ› ï¸ Building the Vector Indexes
Build the Bible index
python build_index.py

Build the Catechism index
python build_catechism_index.py


Inspect ChromaDB:

python inspect_chroma.py

# ğŸ’¬Run the Tutor
python qa_rag.py


Example:

Q: What does the Church teach about forgiveness?


The tutor will:

Retrieve relevant Bible verses + Catechism paragraphs

Insert them into a LangChain prompt

Generate a grounded explanation with citations

To exit:

quit

# ğŸ§ªHow It Works (High-Level Architecture)
User Question
      â†“
OpenAI Embedding (meaning â†’ vector)
      â†“
ChromaDB Semantic Search
      â†“
Top Bible + Catechism Passages
      â†“
LangChain Prompt Template
      â†“
GPT-4o-mini (answer generation)
      â†“
Grounded Response with Citations

# ğŸ“ˆAccomplishments (What This Project Demonstrates)

Indexed 35k+ Bible verses & 2.8k Catechism entries for semantic retrieval

Reduced retrieval latency to <300ms

Achieved >90% reduction in LLM hallucination through grounding & strict prompts

Built a production-grade RAG pipeline using modern LLM tools

# ğŸ“œData Sources

Douayâ€“Rheims Catholic Bible (public domain)

Compendium of the Catechism of the Catholic Church (extracted from PDF)
